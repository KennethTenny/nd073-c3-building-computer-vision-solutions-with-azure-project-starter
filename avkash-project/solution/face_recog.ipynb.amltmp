{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade azure-cognitiveservices-vision-face"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-vision-face\n",
            "  Downloading azure_cognitiveservices_vision_face-0.5.0-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.0 MB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: msrest>=0.5.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cognitiveservices-vision-face) (0.6.21)\n",
            "Requirement already satisfied, skipping upgrade: azure-common~=1.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from azure-cognitiveservices-vision-face) (1.1.27)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: requests~=2.16 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.25.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-face) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.25.11)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-face) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-face) (1.15.0)\n",
            "Installing collected packages: azure-cognitiveservices-vision-face\n",
            "Successfully installed azure-cognitiveservices-vision-face-0.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1621492132726
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import io\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from io import BytesIO\n",
        "# To install this module, run:\n",
        "# python -m pip install Pillow\n",
        "from PIL import Image, ImageDraw\n",
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person\n",
        "from azure.cognitiveservices.vision.face.models import Emotion\n",
        "from azure.cognitiveservices.vision.face.models import FaceAttributeType, HairColorType, TrainingStatusType, Person"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621495769645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Key's and Authenticate\n",
        "ENDPOINT = \"https://face-emotion1.cognitiveservices.azure.com/\"\n",
        "KEY = \"\"\n",
        "\n",
        "# Create an authenticated FaceClient.\n",
        "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621492459203
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect a face in an image that contains a single face\n",
        "single_face_image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/John_F._Kennedy%2C_White_House_color_photo_portrait.jpg/1200px-John_F._Kennedy%2C_White_House_color_photo_portrait.jpg'\n",
        "single_image_name = os.path.basename(single_face_image_url)\n",
        "\n",
        "# We use detection model 3 to get better performance.\n",
        "detected_faces = face_client.face.detect_with_url(url=single_face_image_url, return_face_attributes=[FaceAttributeType.emotion])\n",
        "\n",
        "if not detected_faces:\n",
        "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
        "\n",
        "# Display the detected face ID in the first single-face image.\n",
        "# Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
        "print('Detected face ID from', single_image_name, ':')\n",
        "for face in detected_faces: \n",
        "    print (face.face_id)\n",
        "    print (face.face_attributes.emotion)\n",
        "    print (face.face_landmarks)\n",
        "print()\n",
        "\n",
        "# Save this ID for use in Find Similar\n",
        "first_image_face_ID = detected_faces[0].face_id"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected face ID from 1200px-John_F._Kennedy%2C_White_House_color_photo_portrait.jpg :\n",
            "01ab1e01-259e-414b-a974-8b0059d49524\n",
            "{'additional_properties': {}, 'anger': 0.0, 'contempt': 0.0, 'disgust': 0.0, 'fear': 0.0, 'happiness': 1.0, 'neutral': 0.0, 'sadness': 0.0, 'surprise': 0.0}\n",
            "None\n",
            "\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621496142962
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}