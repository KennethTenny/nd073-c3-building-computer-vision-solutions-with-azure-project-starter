{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Analysis\n",
    "- https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/intro-to-spatial-analysis-public-preview\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating flight manifest\n",
    "\n",
    "- Flight No | Origin | Destination  | Date | Time | First Name | Last Name | Seat # | Date of Birth\n",
    "\n",
    "\n",
    "## Data Provided by the passanger \n",
    "- Boarding Pass\n",
    "    - First Name, Last Name\n",
    "    - Seat # \n",
    "    - Date \n",
    "    - Flight No\n",
    "    - Origin and Destination\n",
    "- Driving License ID (Optional Passport Image)\n",
    "  - First Name, Last Name, DoB\n",
    "  - Face Pic\n",
    "- The Passanger Photo/30 second video\n",
    "  - Considered the real face seen by the Airport Kiosk\n",
    "  - This 30 second video is considered the real-time view of passener at the Kiosk \n",
    "\n",
    "## How it works?\n",
    "- Input \n",
    "    - The passenger provides boarding pass and ID \n",
    "    - Passenger also provides a 30 second video to \n",
    "    - Passenger baggage xray photos are provided\n",
    "- Output\n",
    "    - Kisok Identifies and display the following message:\n",
    "        - Dear {Mr|Mrs} X Y, \n",
    "        - You are welcome to the today's flight No XXXX from Origin to Destination\n",
    "        - Your seat # is XYZ\n",
    "        - The weather at your destination is XXX and the temperature is NNN\n",
    "    - Kiosk also does the following internal processing\n",
    "        - ID photo validation matched with given photo - X% above threshold\n",
    "        - Match the other passengers from the same family also \n",
    "        - Collect passenger emotion as positive or negative feedback \n",
    "    - Kiosk also checks the baggage photos to identify prohibited items\n",
    "        - flag baggage for prohibited items and recognize the correct owner from ID and Boarding pass\n",
    "    - Upload all the validated data to server as table\n",
    "\n",
    "## Exercise:\n",
    "- Create form recognizer for boarding pass identification to extract info\n",
    "    - Get \n",
    "        First Name, Last Name | Seat # | Flight Date | Flight No | Origin | Destination\n",
    "- Use pre-train ID recognizer to extract ID specific info\n",
    "    - Get Male | Female\n",
    "    - Get First Name, Last Name, Dob\n",
    "- Use passenger photos to identify person in the photo\n",
    "- Use 30 second video to extract\n",
    "    - Person photos and recognize the identiy\n",
    "    - Identify emotion in the photo and display at the prompt\n",
    "    - Collect emotion as overall Kios feedback \n",
    "- Identify prohibited items in the luggage from custom model\n",
    "    - Build a custom model to identify {Gun/knife/hand grenade} from x-ray luggage images\n",
    "- Read data from Azure Blob storage\n",
    "- Write data back to Azure Blob Storage\n",
    "\n",
    "\n",
    "## Standout Topics\n",
    "- Check current time and see if the person is 4 hours within the flight time or Late at the gate\n",
    "- Passenger can drop their business card and a winner will be decided to will a free flight ticket\n",
    "    - Create a system to collect business card data using Business Card recognizer\n",
    "    - Save all the colleted info into a table\n",
    "    - Select a random winner from the business user list\n",
    "- Use a 30 second video of a celebrity and match him/her with flight manifest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Outline and Duration - Total 5 Hours\n",
    "\n",
    "- ### A. Problem Definition & System Design (objective 1) - (60 min)\n",
    "    - Problem Details\n",
    "    - Flight Manifest, Saved at Azure Blob\n",
    "    - Boarding Pass desing and passenger boarding pass\n",
    "    - End to End project walkthrough\n",
    "    - Describe Input Data\n",
    "    - Describe Output Data\n",
    "    - Kiosk Design and Greeting's Display\n",
    "\n",
    "- ### B. Applying Azure Form Recognizer to collect text date from various images (60 Min)\n",
    "    - Collect personal information from driving license using pre-built ID recognizer\n",
    "    - Collect personal information from Business Card using pre-built business card recognizer\n",
    "    - Create a custom form recognier model to collect text data from a flight boarding pass\n",
    "    - Use custom boarding pass recognizer model to collect passenger information from a flight boarding pass \n",
    "    - Cross reference the boarding pass information from flight manifest \n",
    "\n",
    "\n",
    "- ### C. Applying Azure Facial Recognition, Video Analysis & Insight to index and analyze faces and emotions within faces (60 min)\n",
    "    - Based on a collection of individual photos, build a model to identify a person \n",
    "    - Extract different emotion from faces using pre-built model\n",
    "    - Process video to generate key-frames\n",
    "    - Collect faces from the video and then Identify faces from the collect frames\n",
    "    - Collect emotions from faces in the video\n",
    "\n",
    "\n",
    "- ### D. Applying Azure Custom Vision to create custom image recognition model (60 Min)\n",
    "    - Creating a custom Image Recognition Model using prohibited item inside checked baggage\n",
    "    - Train and validate the custom model\n",
    "    - Use the model to identify and flag suspected luggage from xray vision images\n",
    "\n",
    "- ### E. Combining everything together (30 Min)\n",
    "    - Create the final solution by integrating various data streams and general final results\n",
    "    - Display Kiosk message based on various data inputs and analysis\n",
    "    - Upload final result data and analytics securely at Azure blob as update flight manifest \n",
    "\n",
    "- ### F. Application Deployment and Monitoring (30 Min)\n",
    "    - Deploy and monitor system performance from Azure Portal. \n",
    "    - Manage/Monitor system via console and create performance report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 1: Design computer vision applications to solve a business problem based on a given use case\n",
    "- Describe considerations for creating computer vision applications\n",
    "- Identify Azure computer vision services for solutions given a scenario\n",
    "- Identify data considerations and sources for Azure computer vision solutions\n",
    "- Provision and consume Azure computer vision APIs\n",
    "- Describe disclosure recommendations related to spatial or facial recognition\n",
    "- Exercises: Given a business scenario or use case, create requirements documentation, architecture diagrams, and high level descriptions of solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 2: Extract text information from digital content within a business use case or scenario\n",
    "- Extracting personal, business and documnt specific information from various digital documents i.e. driving license, business card, receipts etc using pre-built recognizer\n",
    "- Create a custom form recognier model to collect text data from a digital document\n",
    "- Collecting processed information, analyze based on provided logic and the store into azure blob storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 3: Process video and images to extract faces and facial landmarks, emotions and various other face specific information\n",
    "- Based on a collection of individual photos, build a model to identify a person \n",
    "- Processing video to generate key-frames, collecting and grouping faces, match with existing known (train) faces\n",
    "- Collect emotions from faces using pre-built model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Learning Objective 4: Creating custom image classification and object detection solutions\n",
    "- Using image classification and object detection pre-build services and pre-trained model in Azure Computer vision service to identify various object types\n",
    "- Training a custom image classification and object detection model by providing various images and then using traing model in different business specific usage\n",
    "- Improve custom model performance and then deploying as prediction service endpoint, using prediction service programmaticaly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objective 5: Building, deploying and finally monitoring Azure computer vision solutions  \n",
    "\n",
    "- Azure computer vision solution Deplyment, monitoring and Management, \n",
    "- Adding security to application along with extended logging and enhance diagnostics \n",
    "- Cost estimation strategy, Ethical and Bias consideration of AI solutions and data collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
